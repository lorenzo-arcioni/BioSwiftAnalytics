{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Comprehensive Annotation Reports\n",
    "\n",
    "This Jupyter notebook is designed to generate a report file based on annotation results obtained from annotation tools such as BLAST or Diamond. To use this notebook, users must have both the annotation results in TSV format and a table containing additional information about the transcripts. By leveraging the power of Jupyter notebooks, users can interactively visualize and analyze their annotation results, generating a comprehensive report that includes detailed statistics and data visualizations. The notebook's intuitive user interface and modular design make it easy to customize the report based on specific research needs. With its ability to quickly and efficiently generate reports from annotation data, this Jupyter notebook is an invaluable tool for researchers working with transcriptomic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the user must customize the generation parameters (by appropriately modifying the variables) following the instructions in the comments in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the names (or paths) of the tsv files\n",
    "files = [\n",
    "    \"../bombina_2/bombina_corset_DEGS__unk_not-unk.fasta.transdecoder.cds_nr.tsv\",\n",
    "    \"../bombina_2/bombina_corset_DEGS__unk_not-unk.fasta.transdecoder.cds_tr.tsv\",\n",
    "    \"../bombina_2/bombina_corset_DEGS__unk_not-unk.fasta.transdecoder.cds_sp.tsv\"\n",
    "] \n",
    "\n",
    "# Insert the titles of the graph\n",
    "title = \"bombina_pachypus_blastx\"\n",
    "\n",
    "# Insert the databases names (the order must match the result files order)\n",
    "databases_names =[\n",
    "    \"Nr\", \n",
    "    \"TrEMBL\",\n",
    "    \"Swiss-Prot\",\n",
    "]\n",
    "\n",
    "# Insert the table (with additional informations) path\n",
    "table_path = \"../bombina_2/bombina_unref_vs_not_unkref_table_padj_0.05----log2fc_1.tsv\"\n",
    "\n",
    "# Insert the path of the report\n",
    "path = \"../bombina_2/\" + title\n",
    "\n",
    "# Set the outformat\n",
    "# e.g. \n",
    "# outfmt = \"qseqid qlen sseqid sallseqid slen qstart qend sstart send qseq full_qseq sseq full_sseq evalue bitscore score length pident nident mismatch positive gapopen gaps ppos qframe btop cigar staxids sscinames sskingdoms skingdoms sphylums stitle salltitles qcovhsp scovhsp qtitle qqual full_qqual qstrand\"\n",
    "# If there are column names in the file then set outfmt = None\n",
    "outfmt = \"qseqid qlen sseqid sallseqid slen qstart qend sstart send qseq full_qseq sseq full_sseq evalue bitscore score length pident nident mismatch positive gapopen gaps ppos qframe btop cigar staxids sscinames sskingdoms skingdoms sphylums stitle salltitles qcovhsp scovhsp qtitle qqual full_qqual qstrand\"\n",
    "\n",
    "# Columns names (modify this list by inserting the column names of the report)\n",
    "features = [\"transcript\", \"row\", \"log2FoldChange\", \"padj\", \n",
    "            \"protein_accession\", \"sequence_identity\", \"alignment_length\", \n",
    "            \"evalue\", \"database\", \"gene\", \"locus_name\", \"sequence_description\",\n",
    "            \"sequence_length\", \"organism\", \"protein_product\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on float64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m     df_tmp[\u001b[39m'\u001b[39m\u001b[39mprotein_product\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_tmp\u001b[39m.\u001b[39mstitle\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: get_protein_function(x))\n\u001b[1;32m     84\u001b[0m     df_tmp[\u001b[39m'\u001b[39m\u001b[39mlocus_name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_tmp\u001b[39m.\u001b[39msseqid\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: get_locus_name(x))\n\u001b[0;32m---> 86\u001b[0m     df_tmp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(df_tmp, table, on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtranscript\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     88\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df, df_tmp[features]])\n\u001b[1;32m     90\u001b[0m df\u001b[39m.\u001b[39msort_values([\u001b[39m'\u001b[39m\u001b[39mtranscript\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mevalue\u001b[39m\u001b[39m'\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/datas/lib/python3.10/site-packages/pandas/core/reshape/merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m--> 110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    111\u001b[0m         left,\n\u001b[1;32m    112\u001b[0m         right,\n\u001b[1;32m    113\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m    114\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m    115\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m    116\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m    117\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m    118\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m    119\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    120\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m    121\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m    122\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/miniconda3/envs/datas/lib/python3.10/site-packages/pandas/core/reshape/merge.py:707\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    699\u001b[0m (\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[1;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[1;32m    702\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[1;32m    703\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_merge_keys()\n\u001b[1;32m    705\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m--> 707\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_coerce_merge_keys()\n\u001b[1;32m    709\u001b[0m \u001b[39m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[39m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[39m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39mif\u001b[39;00m validate \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/datas/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1340\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[39m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m     \u001b[39melif\u001b[39;00m (\n\u001b[1;32m   1336\u001b[0m         inferred_left \u001b[39min\u001b[39;00m string_types \u001b[39mand\u001b[39;00m inferred_right \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m string_types\n\u001b[1;32m   1337\u001b[0m     ) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   1338\u001b[0m         inferred_right \u001b[39min\u001b[39;00m string_types \u001b[39mand\u001b[39;00m inferred_left \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m string_types\n\u001b[1;32m   1339\u001b[0m     ):\n\u001b[0;32m-> 1340\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1342\u001b[0m \u001b[39m# datetimelikes must match exactly\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \u001b[39melif\u001b[39;00m needs_i8_conversion(lk\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m needs_i8_conversion(rk\u001b[39m.\u001b[39mdtype):\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on float64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "def get_transcripts_from_id(transcripts, table):\n",
    "    transcripts = transcripts.unique()\n",
    "\n",
    "    dic = dict()\n",
    "\n",
    "    for t in transcripts:\n",
    "        for x in table.transcript:\n",
    "            if re.match(x, t):\n",
    "                dic[t] = x\n",
    "    return dic\n",
    "\n",
    "df = pd.DataFrame()\n",
    "table = pd.read_csv(table_path, sep='\\t')\n",
    "for i in range(len(files)):\n",
    "\n",
    "    #Import the dataset\n",
    "    df_tmp = pd.read_csv(files[i], sep=\"\\t\", names=outfmt.split())\n",
    "\n",
    "    df_tmp['transcript'] = df_tmp['qseqid'].map(get_transcripts_from_id(df_tmp['qseqid'], table))\n",
    "    df_tmp['row'] = title\n",
    "    df_tmp['sequence_identity'] = df_tmp.pident\n",
    "    df_tmp['alignment_length'] = df_tmp.length\n",
    "    df_tmp['evalue'] = df_tmp.evalue\n",
    "    df_tmp['sequence_description'] = df_tmp.stitle\n",
    "    df_tmp['sequence_length'] = df_tmp.slen\n",
    "    df_tmp['database'] = databases_names[i]\n",
    "\n",
    "    if \"OS=\" not in df_tmp.stitle[0]:    \n",
    "        def get_sciname(x):\n",
    "            \n",
    "            os_index = - x[::-1].index('[')\n",
    "\n",
    "            return x[os_index:-1]\n",
    "\n",
    "        # Useful functions\n",
    "        def get_protein_function(x):\n",
    "\n",
    "            x_l = x.split(\" \")\n",
    "\n",
    "            return ' '.join(x_l[1:x_l.index(next(x for x in x_l if x.startswith('[')))])\n",
    "        \n",
    "        def get_protein_accession(x):\n",
    "            return x.split(\" \")[0]\n",
    "        \n",
    "        def get_locus_name(x):\n",
    "            return None\n",
    "        \n",
    "        def get_gene(x):\n",
    "            return None\n",
    "    else:\n",
    "        def get_sciname(x):\n",
    "\n",
    "            os_index = x.index('OS=')\n",
    "            ox_index = x.index('OX=')\n",
    "\n",
    "            return x[os_index+3:ox_index-1]\n",
    "\n",
    "        # Useful functions\n",
    "        def get_protein_function(x):\n",
    "\n",
    "            x_l = x.split(\" \")\n",
    "\n",
    "            return ' '.join(x_l[1:x_l.index(next(x for x in x_l if x.startswith('OS=')))])\n",
    "        \n",
    "        def get_protein_accession(x):\n",
    "            return x.split(\"|\")[1]\n",
    "        \n",
    "        def get_locus_name(x):\n",
    "            return x.split(\"|\")[2]\n",
    "        \n",
    "        def get_gene(x):\n",
    "\n",
    "            try:\n",
    "                gn_index = x.index('GN=')\n",
    "                pe_index = x.index('PE=')\n",
    "            except:\n",
    "                return None\n",
    "            return x[gn_index+3:pe_index-1]\n",
    "        \n",
    "    df_tmp['gene'] = df_tmp.stitle.apply(lambda x: get_gene(x))\n",
    "    df_tmp['organism'] = df_tmp.stitle.apply(lambda x: get_sciname(x))\n",
    "    df_tmp['protein_accession'] = df_tmp.sseqid.apply(lambda x: get_protein_accession(x))\n",
    "    df_tmp['protein_product'] = df_tmp.stitle.apply(lambda x: get_protein_function(x))\n",
    "    df_tmp['locus_name'] = df_tmp.sseqid.apply(lambda x: get_locus_name(x))\n",
    "\n",
    "    df_tmp = pd.merge(df_tmp, table, on='transcript')\n",
    "\n",
    "    df = pd.concat([df, df_tmp[features]])\n",
    "\n",
    "df.sort_values(['transcript', 'evalue'], inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to remove repetitive information (e.g. trasncript name ecc..) run the cell below (you can also modify given list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.duplicated(subset=['transcript', 'row', 'log2FoldChange', 'padj']), 'transcript':'padj'] = ''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to save the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(path + '.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TrEMBL and Swiss-Prot link: https://www.uniprot.org/uniprotkb/A0A8C5RT80/entry\n",
    "NR: https://www.ncbi.nlm.nih.gov/gene/?term=A0A6P7WME3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
