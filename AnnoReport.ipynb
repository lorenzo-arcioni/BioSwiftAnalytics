{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Report: Multi-database Annotation Summary\n",
    "\n",
    "This Jupyter notebook is designed to generate a report file based on annotation results obtained from annotation tools such as BLAST or Diamond. To use this notebook, users must have both the annotation results in TSV format and a table containing additional information about the transcripts. By leveraging the power of Jupyter notebooks, users can interactively visualize and analyze their annotation results, generating a comprehensive report that includes detailed statistics and data visualizations. The notebook's intuitive user interface and modular design make it easy to customize the report based on specific research needs. With its ability to quickly and efficiently generate reports from annotation data, this Jupyter notebook is an invaluable tool for researchers working with transcriptomic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, run the following cell for defining useful functions and loading the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "from openpyxl.utils import get_column_letter\n",
    "import os\n",
    "import time\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def get_transcripts_from_id(transcripts, table):\n",
    "    transcripts = transcripts.unique()\n",
    "\n",
    "    dic = dict()\n",
    "\n",
    "    for t in transcripts:\n",
    "        for x in table.transcript:\n",
    "            if t.startswith(x):\n",
    "                dic[t] = x\n",
    "    return dic\n",
    "\n",
    "def make_hyperlink(sseqid, database):\n",
    "    \n",
    "    try:\n",
    "        if database.lower() == 'nr':\n",
    "            protein_accession = sseqid.split(\" \")[0]\n",
    "            url = \"https://www.ncbi.nlm.nih.gov/gene/?term={}\"\n",
    "        else:\n",
    "            protein_accession = sseqid.split(\"|\")[1]\n",
    "            url = \"https://www.uniprot.org/uniprotkb/{}/entry\"\n",
    "    except:\n",
    "        print(sseqid)\n",
    "        return \"\"\n",
    "        \n",
    "    return '=HYPERLINK(\"%s\", \"%s\")' % (url.format(protein_accession), protein_accession)\n",
    "\n",
    "def get_accession(sseqid, database):\n",
    "\n",
    "    if database.lower() == 'nr':\n",
    "        try:\n",
    "            return sseqid.split(\" \")[0]\n",
    "        except:\n",
    "            return \"\"\n",
    "    else:\n",
    "        try:\n",
    "            return sseqid.split(\"|\")[1]\n",
    "        except:\n",
    "            return \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the user must customize the generation parameters (by appropriately modifying the variables) following the instructions in the comments in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the names (or paths) of the tsv files\n",
    "files = [\n",
    "    \"../culex_pipiens/blast_nr.tsv\",\n",
    "    \"../culex_pipiens/blast_tr.tsv\",\n",
    "    \"../culex_pipiens/blast_sp.tsv\"\n",
    "] \n",
    "\n",
    "# Insert the titles of the graph\n",
    "title = \"Blast\"\n",
    "\n",
    "# Insert the databases names (the order must match the result files order)\n",
    "databases_names =[\n",
    "    \"Nr\", \n",
    "    \"TrEMBL\",\n",
    "    \"Swiss-Prot\",\n",
    "]\n",
    "\n",
    "# Insert the table (with additional informations) path\n",
    "table_path = \"./culex_pipiens/tables\"\n",
    "\n",
    "# Insert the path of the report\n",
    "path = \"./results/\" + title\n",
    "\n",
    "# Set the outformat\n",
    "# e.g. \n",
    "# outfmt = \"qseqid qlen sseqid sallseqid slen qstart qend sstart send qseq full_qseq sseq full_sseq evalue bitscore score length pident nident mismatch positive gapopen gaps ppos qframe btop cigar staxids sscinames sskingdoms skingdoms sphylums stitle salltitles qcovhsp scovhsp qtitle qqual full_qqual qstrand\"\n",
    "# If there are column names in the file then set outfmt = None\n",
    "#outfmt = \"qseqid qlen sseqid sallseqid slen qstart qend sstart send qseq full_qseq sseq full_sseq evalue bitscore score length pident nident mismatch positive gapopen gaps ppos qframe btop cigar stitle salltitles qcovhsp scovhsp qtitle qqual full_qqual qstrand\"\n",
    "outfmt = None\n",
    "# Columns names (modify this list by inserting the column names of the report)\n",
    "features = [\"transcript\", \"log2FoldChange\", \"padj\", \n",
    "            \"protein_accession\", \"sequence_identity\", \"alignment_length\", \n",
    "            \"evalue\", \"database\", \"gene\", \"locus_name\", \"sequence_description\",\n",
    "            \"sequence_length\", \"organism\", \"protein_product\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run the cell below to build the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(table):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    table = pd.read_csv(table_path + \"/\" + table, sep='\\t')\n",
    "    table.index.name = 'transcript'\n",
    "    tools = []\n",
    "    table.reset_index(inplace=True)\n",
    "\n",
    "    for i in range(len(files)):\n",
    "\n",
    "        #Import the dataset\n",
    "        if outfmt == None:\n",
    "            df_tmp = pd.read_csv(files[i], sep=\"\\t\", low_memory=False)\n",
    "        else:\n",
    "            df_tmp = pd.read_csv(files[i], sep=\"\\t\", names=outfmt.split(), low_memory=False)\n",
    "\n",
    "        df_tmp['qseqid'] = df_tmp['qseqid'].map(get_transcripts_from_id(df_tmp['qseqid'], table))\n",
    "        df_tmp['database'] = databases_names[i]\n",
    "\n",
    "        tools = df_tmp.row.unique().tolist()\n",
    "        for row in tools:\n",
    "            df_tmp[row] = (df_tmp[\"row\"] == row).astype(int)\n",
    "        df_tmp = df_tmp.groupby([\"qseqid\", \"sseqid\", \"pident\", \"slen\", \"stitle\", \"length\", \"evalue\", \"database\"]).sum().reset_index()\n",
    "        for row in tools:\n",
    "            df_tmp[row] = df_tmp[row].map(lambda x: row if x == 1 else \"\")\n",
    "        df_tmp.drop(\"row\", axis=1, inplace=True)\n",
    "\n",
    "        df_tmp.rename(columns={'pident': 'sequence_identity',\n",
    "                                'length': 'alignment_length',\n",
    "                                'stitle': 'sequence_description',\n",
    "                                'slen':   'sequence_length'\n",
    "        }, inplace=True)\n",
    "\n",
    "        if \"OS=\" not in df_tmp.sequence_description[0]:    \n",
    "            def get_sciname(x):\n",
    "                \n",
    "                try:\n",
    "                    os_index = - x[::-1].index('[')\n",
    "                except:\n",
    "                    return \"\"\n",
    "\n",
    "                return x[os_index:-1]\n",
    "\n",
    "            # Useful functions\n",
    "            def get_protein_function(x):\n",
    "\n",
    "                x_l = x.split(\" \")\n",
    "\n",
    "                try:\n",
    "                    nex = ' '.join(x_l[1:x_l.index(next(x for x in x_l if x.startswith('[')))])\n",
    "                except:\n",
    "                    return \"\"\n",
    "\n",
    "                return nex\n",
    "            \n",
    "            def get_locus_name(x):\n",
    "                return None\n",
    "            \n",
    "            def get_gene(x):\n",
    "                return None\n",
    "        else:\n",
    "            def get_sciname(x):\n",
    "\n",
    "                try:\n",
    "                    os_index = x.index('OS=')\n",
    "                    ox_index = x.index('OX=')\n",
    "                except:\n",
    "                    return \"\"\n",
    "\n",
    "                return x[os_index+3:ox_index-1]\n",
    "\n",
    "            # Useful functions\n",
    "            def get_protein_function(x):\n",
    "\n",
    "                x_l = x.split(\" \")\n",
    "\n",
    "                try:\n",
    "                    nex = ' '.join(x_l[1:x_l.index(next(x for x in x_l if x.startswith('OS=')))])\n",
    "                except:\n",
    "                    return \"\"\n",
    "\n",
    "                return nex\n",
    "            \n",
    "            def get_locus_name(x):\n",
    "                try:\n",
    "                    return x.split(\"|\")[1]\n",
    "                except:\n",
    "                    return \"\"\n",
    "            \n",
    "            def get_gene(x):\n",
    "\n",
    "                try:\n",
    "                    gn_index = x.index('GN=')\n",
    "                    pe_index = x.index('PE=')\n",
    "                except:\n",
    "                    return None\n",
    "                return x[gn_index+3:pe_index-1]\n",
    "            \n",
    "        df_tmp['gene'] = df_tmp.sequence_description.apply(lambda x: get_gene(x))\n",
    "        df_tmp['organism'] = df_tmp.sequence_description.apply(lambda x: get_sciname(x))\n",
    "        df_tmp['protein_accession'] = df_tmp.apply(lambda x: make_hyperlink(x.sseqid, x.database), axis=1)\n",
    "        df_tmp['protein_product'] = df_tmp.sequence_description.apply(lambda x: get_protein_function(x))\n",
    "        df_tmp['locus_name'] = df_tmp.sseqid.apply(lambda x: get_locus_name(x))\n",
    "\n",
    "        df_tmp = pd.merge(df_tmp, table, left_on='qseqid', right_on='transcript', how='inner')\n",
    "\n",
    "        df = pd.concat([df, df_tmp[[\"transcript\"] + tools + features[1:]]])\n",
    "\n",
    "        print(\"File\", files[i], \"done!\")\n",
    "\n",
    "    df.sort_values(['transcript', 'evalue'], inplace=True)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df = df.groupby('transcript').head(20)\n",
    "\n",
    "    df.loc[df.duplicated(subset=['transcript', 'log2FoldChange', 'padj']), ['transcript', 'log2FoldChange', 'padj']] = ''\n",
    "    #unmatched_transcript = pd.Series(list(set(table.transcript) - set(df.transcript)), name='unmatched_transcript')\n",
    "\n",
    "    df = df[[\"transcript\"] + tools + features[1:]]\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_xlsx(df, path, t):\n",
    "    df_writer = pd.ExcelWriter(path + \"_\" + t.split(\"/\")[-1] + '.xlsx') \n",
    "\n",
    "    # Write the DataFrame to the working ExcelWriter\n",
    "    df.to_excel(df_writer, sheet_name='report', index=False)\n",
    "\n",
    "    # Get the xlsxwriter workbook and worksheet objects\n",
    "    worksheet = df_writer.sheets['report']\n",
    "\n",
    "    # Set the column width\n",
    "    for column in range(df.shape[1]):\n",
    "        column_length = max(df.iloc[:, column].astype(str).map(len).max(), len(df.columns[column])) + 3\n",
    "        column_letter = get_column_letter(column + 1)\n",
    "        worksheet.column_dimensions[column_letter].width = column_length\n",
    "\n",
    "    # Salva il foglio di lavoro\n",
    "    df_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing UP-reg_padj_0.05--log2fc_1_table_ResistantCOST____ResistantDFB.txt\n",
      "File ./culex_pipiens/blast_nr.tsv done!\n",
      "File ./culex_pipiens/blast_tr.tsv done!\n",
      "File ./culex_pipiens/blast_sp.tsv done!\n",
      "Table UP-reg_padj_0.05--log2fc_1_table_ResistantCOST____ResistantDFB.txt done in --- 75.82250189781189 seconds ---\n",
      "Analysing UP-reg_padj_0.05--log2fc_1_table_SusceptibleCOST____SusceptibleDFB.txt\n",
      "File ./culex_pipiens/blast_nr.tsv done!\n",
      "File ./culex_pipiens/blast_tr.tsv done!\n",
      "File ./culex_pipiens/blast_sp.tsv done!\n",
      "Table UP-reg_padj_0.05--log2fc_1_table_SusceptibleCOST____SusceptibleDFB.txt done in --- 82.96428084373474 seconds ---\n",
      "Analysing DOWN-reg_padj_0.05--log2fc_1_table_SusceptibleCOST____ResistantCOST.txt\n",
      "File ./culex_pipiens/blast_nr.tsv done!\n",
      "File ./culex_pipiens/blast_tr.tsv done!\n",
      "File ./culex_pipiens/blast_sp.tsv done!\n",
      "Table DOWN-reg_padj_0.05--log2fc_1_table_SusceptibleCOST____ResistantCOST.txt done in --- 15.278906345367432 seconds ---\n",
      "Analysing DOWN-reg_padj_0.05--log2fc_1_table_SusceptibleDFB____ResistantDFB.txt\n",
      "File ./culex_pipiens/blast_nr.tsv done!\n",
      "File ./culex_pipiens/blast_tr.tsv done!\n",
      "File ./culex_pipiens/blast_sp.tsv done!\n",
      "Table DOWN-reg_padj_0.05--log2fc_1_table_SusceptibleDFB____ResistantDFB.txt done in --- 96.82188439369202 seconds ---\n",
      "Analysing DOWN-reg_padj_0.05--log2fc_1_table_SusceptibleCOST____SusceptibleDFB.txt\n",
      "File ./culex_pipiens/blast_nr.tsv done!\n",
      "File ./culex_pipiens/blast_tr.tsv done!\n",
      "File ./culex_pipiens/blast_sp.tsv done!\n",
      "Table DOWN-reg_padj_0.05--log2fc_1_table_SusceptibleCOST____SusceptibleDFB.txt done in --- 103.3277747631073 seconds ---\n",
      "Analysing UP-reg_padj_0.05--log2fc_1_table_SusceptibleDFB____ResistantDFB.txt\n",
      "File ./culex_pipiens/blast_nr.tsv done!\n",
      "File ./culex_pipiens/blast_tr.tsv done!\n",
      "File ./culex_pipiens/blast_sp.tsv done!\n",
      "Table UP-reg_padj_0.05--log2fc_1_table_SusceptibleDFB____ResistantDFB.txt done in --- 50.232518911361694 seconds ---\n",
      "Analysing DOWN-reg_padj_0.05--log2fc_1_table_ResistantCOST____ResistantDFB.txt\n",
      "File ./culex_pipiens/blast_nr.tsv done!\n",
      "File ./culex_pipiens/blast_tr.tsv done!\n",
      "File ./culex_pipiens/blast_sp.tsv done!\n",
      "Table DOWN-reg_padj_0.05--log2fc_1_table_ResistantCOST____ResistantDFB.txt done in --- 146.12441039085388 seconds ---\n",
      "Analysing UP-reg_padj_0.05--log2fc_1_table_SusceptibleCOST____ResistantCOST.txt\n",
      "File ./culex_pipiens/blast_nr.tsv done!\n",
      "File ./culex_pipiens/blast_tr.tsv done!\n",
      "File ./culex_pipiens/blast_sp.tsv done!\n",
      "Table UP-reg_padj_0.05--log2fc_1_table_SusceptibleCOST____ResistantCOST.txt done in --- 22.397655963897705 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Save the super-table for each table in the tables directory\n",
    "for t in os.listdir(table_path):\n",
    "\n",
    "    print(\"Analysing\", t)\n",
    "\n",
    "    # get initial time\n",
    "    start_time = time.time()\n",
    "\n",
    "    df = generate_df(t)\n",
    "\n",
    "    df.head()\n",
    "\n",
    "    df.to_csv(path + \"_\" + t + '.tsv', sep='\\t', index=False)\n",
    "\n",
    "    generate_xlsx(df, path, t)\n",
    "\n",
    "    print(\"Table\", t, \"done in\", \"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
