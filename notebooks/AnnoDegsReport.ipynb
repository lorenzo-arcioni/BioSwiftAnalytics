{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degs Annotation Report: Multi-database Annotation Summary\n",
    "\n",
    "This Jupyter notebook is designed to generate a report file based on annotation results obtained from annotation tools such as BLAST or Diamond. To use this notebook, users must have both the annotation results in TSV format and a table containing additional information about the transcripts (usually obtained with DeSeq2 software). The notebook's intuitive user interface and modular design make it easy to customize the report based on specific research needs. With its ability to quickly and efficiently generate reports from annotation data, this Jupyter notebook is an invaluable tool for researchers working with transcriptomic data.\n",
    "\n",
    "*Remember:* The tsv files **must** contain at least the following columns: \"qseqid\", \"sseqid\", \"pident\", \"slen\", \"stitle\", \"length\", \"evalue\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, run the following cell for defining useful functions and loading the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "from openpyxl.utils import get_column_letter\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Define useful functions\n",
    "\n",
    "# Get the transcript IDs from the table\n",
    "def get_transcripts_from_id(transcripts, table):\n",
    "    transcripts = transcripts.unique()\n",
    "\n",
    "    dic = dict()\n",
    "\n",
    "    for t in transcripts:\n",
    "        for x in table.transcript:\n",
    "            if t.startswith(x):\n",
    "                dic[t] = x\n",
    "    return dic\n",
    "\n",
    "# Get the hyperlink from the sseqid\n",
    "def make_hyperlink(sseqid, database):\n",
    "    \n",
    "    try:\n",
    "        if database.lower() == 'nr':\n",
    "            protein_accession = sseqid.split(\" \")[0]\n",
    "            url = \"https://www.ncbi.nlm.nih.gov/gene/?term={}\"\n",
    "        else:\n",
    "            protein_accession = sseqid.split(\"|\")[1]\n",
    "            url = \"https://www.uniprot.org/uniprotkb/{}/entry\"\n",
    "    except:\n",
    "        print(sseqid)\n",
    "        return \"\"\n",
    "        \n",
    "    return '=HYPERLINK(\"%s\", \"%s\")' % (url.format(protein_accession), protein_accession)\n",
    "\n",
    "# Get the accession from the sseqid\n",
    "def get_accession(sseqid, database):\n",
    "\n",
    "    if database.lower() == 'nr':\n",
    "        try:\n",
    "            return sseqid.split(\" \")[0]\n",
    "        except:\n",
    "            return \"\"\n",
    "    else:\n",
    "        try:\n",
    "            return sseqid.split(\"|\")[1]\n",
    "        except:\n",
    "            return \"\"\n",
    "\n",
    "# Get the scientific name from the stitle\n",
    "def get_sciname(x, database):\n",
    "\n",
    "    if database.lower() == 'nr':\n",
    "\n",
    "        try:\n",
    "            os_index = - x[::-1].index('[')\n",
    "        except:\n",
    "            return \"\"\n",
    "\n",
    "        return x[os_index:-1]\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            os_index = x.index('OS=')\n",
    "            ox_index = x.index('OX=')\n",
    "        except:\n",
    "            return \"\"\n",
    "\n",
    "        return x[os_index+3:ox_index-1]\n",
    "\n",
    "# Get the protein function from the stitle\n",
    "def get_protein_function(x, database):\n",
    "\n",
    "    s = '[' if database.lower() == 'nr' else 'OS='\n",
    "    x_l = x.split(\" \")\n",
    "\n",
    "    try:\n",
    "        nex = ' '.join(x_l[1:x_l.index(next(x for x in x_l if x.startswith(s)))])\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "    return nex\n",
    "\n",
    "# Get the locus name from the stitle\n",
    "def get_locus_name(x, database):\n",
    "\n",
    "    if database.lower() == 'nr':\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        return x.split(\"|\")[1]\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# Get the gene from the stitle\n",
    "def get_gene(x, database):\n",
    "\n",
    "    if database.lower() == 'nr':\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        gn_index = x.index('GN=')\n",
    "        pe_index = x.index('PE=')\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    return x[gn_index+3:pe_index-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the user must customize the generation parameters (by appropriately modifying the variables) following the instructions in the comments in the cell below.\n",
    "\n",
    "So once you have filled it (with your data), exec this cell to setting up the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the titles of the graph\n",
    "title = \"Blast-culex_pipiens\"\n",
    "\n",
    "# Insert the table (with additional informations) path\n",
    "table_path = \"../data/tables\"\n",
    "\n",
    "# Insert the path of the report (remember the \"/\" at the end)\n",
    "out_path = \"../results/\"\n",
    "\n",
    "# Set databases names\n",
    "tool_names = [\n",
    "        \"blastp\", \n",
    "        \"blastx\",\n",
    "]\n",
    "\n",
    "# Insert the databases names (the order must match the result files order)\n",
    "databases_names =[\n",
    "    \"Nr\", \n",
    "    \"TrEMBL\",\n",
    "    \"Swiss-Prot\",\n",
    "]\n",
    "\n",
    "# Insert the names (or paths) of the tsv files (remember to follow the same order used when setting the tool_names and databases_names)\n",
    "files = {\n",
    "\n",
    "    'Nr':[\n",
    "        \"../data/culex_pipiens-longest_orf-blastp-nr.tsv\",\n",
    "        \"../data/culex_pipiens-longest_orf-blastx-nr.tsv\",\n",
    "    ],\n",
    "\n",
    "    'TrEMBL':[\n",
    "        \"../data/culex_pipiens-longest_orf-blastp-tr.tsv\",\n",
    "        \"../data/culex_pipiens-longest_orf-blastx-tr.tsv\",\n",
    "    ],\n",
    "\n",
    "    'Swiss-Prot':[\n",
    "        \"../data/culex_pipiens-longest_orf-blastp-sp.tsv\",\n",
    "        \"../data/culex_pipiens-longest_orf-blastx-sp.tsv\"\n",
    "    ],\n",
    "\n",
    "}\n",
    "\n",
    "# Set the outformat\n",
    "# e.g. \n",
    "#outfmt = \"qseqid qlen sseqid sallseqid slen qstart qend sstart send qseq full_qseq sseq full_sseq evalue bitscore score length pident nident mismatch positive gapopen gaps ppos qframe btop cigar staxids sscinames sskingdoms skingdoms sphylums stitle salltitles qcovhsp scovhsp qtitle qqual full_qqual qstrand\"\n",
    "#outfmt = \"qseqid qlen sseqid sallseqid slen qstart qend sstart send qseq full_qseq sseq full_sseq evalue bitscore score length pident nident mismatch positive gapopen gaps ppos qframe btop cigar stitle salltitles qcovhsp scovhsp qtitle qqual full_qqual qstrand\"\n",
    "\n",
    "# If there are column names in the first row of tsv files then set outfmt = None\n",
    "outfmt = \"qseqid qlen sseqid slen evalue bitscore score length pident stitle\"\n",
    "#outfmt = None\n",
    "\n",
    "# Default features to extract, you can change them if you want to modify the report\n",
    "# Columns names (modify this list by inserting the column names of the report)\n",
    "all_features = [\"transcript\", \"log2FoldChange\", \"padj\", \n",
    "            \"protein_accession\", \"sequence_identity\", \"alignment_length\", \n",
    "            \"evalue\", \"database\", \"gene\", \"locus_name\", \"sequence_description\",\n",
    "            \"sequence_length\", \"organism\", \"protein_product\"]\n",
    "\n",
    "features = [\"qseqid\", \"sseqid\", \"pident\", \"slen\", \"stitle\", \"length\", \"evalue\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run the cell below to define the functions that generate the final dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define useful functions\n",
    "\n",
    "def get_dataframe_from_files():\n",
    "\n",
    "    \"\"\"\n",
    "    This function is used to import the whole dataframe from the all tsv files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the features of interest\n",
    "    features = [\"qseqid\", \"sseqid\", \"pident\", \"slen\", \"stitle\", \"length\", \"evalue\"]\n",
    "\n",
    "    # Create an empty dataframe\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over the files\n",
    "    for db in files.keys():\n",
    "\n",
    "        # Iterate over the tools and files\n",
    "        for file, tool in zip(files[db], tool_names):\n",
    "\n",
    "            # Import the tsv dataset.\n",
    "            # If outfmt = None the first row will be used as column names\n",
    "            if outfmt == None:\n",
    "                tmp = pd.read_csv(file, sep=\"\\t\", low_memory=False)\n",
    "            else:\n",
    "                tmp = pd.read_csv(file, sep=\"\\t\", names=outfmt.split(), low_memory=False)\n",
    "\n",
    "            # Extract the features of interest\n",
    "            tmp = tmp[features]\n",
    "\n",
    "            # Add the tool name\n",
    "            tmp['tool'] = tool\n",
    "            \n",
    "            # Add the database name\n",
    "            tmp['database'] = db\n",
    "            \n",
    "            # Concatenate the dataframe with the current one\n",
    "            df = pd.concat([df, tmp])\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_df(df, table):\n",
    "\n",
    "    \"\"\"\n",
    "    This function is used to generate the super-table merging the information contained in the DeSeq2 table with\n",
    "    the alignment information inside the complete dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the table from DeSeq2 table file\n",
    "    table = pd.read_csv(table_path + \"/\" + table, sep='\\t')\n",
    "\n",
    "    # Set the index column name\n",
    "    table.index.name = 'transcript'\n",
    "    table.reset_index(inplace=True)\n",
    "\n",
    "    # Get the relevant transcript IDs from the table\n",
    "    df['qseqid'] = df['qseqid'].map(get_transcripts_from_id(df['qseqid'], table))\n",
    "\n",
    "    # For each tool add the respective column and set it to 0 if the used tool is not the current one and 1 otherwise\n",
    "    for row in tool_names:\n",
    "        df[row] = [row if x == row else '' for x in df['tool']]\n",
    "    \n",
    "    # Group the dataframe by qseqid, sseqid, pident, slen, stitle, length, evalue, database\n",
    "    df = df.groupby([\"qseqid\", \"sseqid\", \"pident\", \"slen\", \"stitle\", \"length\", \"evalue\", \"database\"]).sum().reset_index()\n",
    "    \n",
    "    # Drop the row column\n",
    "    df.drop(\"tool\", axis=1, inplace=True)\n",
    "\n",
    "    # Rename the columns\n",
    "    df.rename(columns={'pident': 'sequence_identity',\n",
    "                       'length': 'alignment_length',\n",
    "                       'stitle': 'sequence_description',\n",
    "                       'slen':   'sequence_length'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Add the gene, organism, protein_accession, protein_product, locus_name columns        \n",
    "    df['gene'] = [get_gene(row['sequence_description'], row['database']) for idx, row in df.iterrows()]\n",
    "    df['organism'] = [get_sciname(row['sequence_description'], row['database']) for idx, row in df.iterrows()]\n",
    "    df['protein_accession'] = df.apply(lambda x: make_hyperlink(x.sseqid, x.database), axis=1)\n",
    "    df['protein_product'] = [get_protein_function(row['sequence_description'], row['database']) for idx, row in df.iterrows()]\n",
    "    df['locus_name'] = [get_locus_name(row['sseqid'], row['database']) for idx, row in df.iterrows()]\n",
    "\n",
    "    # Merge the dataframe with the table\n",
    "    df = pd.merge(df, table, left_on='qseqid', right_on='transcript', how='inner')\n",
    "\n",
    "    # Sort the dataframe by transcript, evalue\n",
    "    df.sort_values(['transcript', 'evalue'], inplace=True)\n",
    "\n",
    "    # Reset the index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Group the dataframe by transcript and take the top 20 rows\n",
    "    df = df.groupby('transcript').head(20)\n",
    "\n",
    "    # Set the duplicated transcript, log2FoldChange and padj to None\n",
    "    df.loc[df.duplicated(subset=['transcript', 'log2FoldChange', 'padj']), ['transcript', 'log2FoldChange', 'padj']] = None\n",
    "    \n",
    "    # Reorder the columns\n",
    "    df = df[[\"transcript\"] + tool_names + all_features[1:]]\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_xlsx(df, path, table):\n",
    "\n",
    "    \"\"\"\n",
    "    This function is used to generate the xlsx file with the super-table.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine\n",
    "    df_writer = pd.ExcelWriter(path + \"_\" + table.split(\"/\")[-1] + '.xlsx') \n",
    "\n",
    "    # Write the DataFrame to the working ExcelWriter\n",
    "    df.to_excel(df_writer, sheet_name='report', index=False)\n",
    "\n",
    "    # Get the xlsxwriter workbook and worksheet objects\n",
    "    worksheet = df_writer.sheets['report']\n",
    "\n",
    "    # Set the column width\n",
    "    for column in range(df.shape[1]):\n",
    "\n",
    "        # Get the max length of the columns\n",
    "        column_length = max(df.iloc[:, column].astype(str).map(len).max(), len(df.columns[column])) + 3\n",
    "\n",
    "        # Setting the column length\n",
    "        column_letter = get_column_letter(column + 1)\n",
    "\n",
    "        # Adjust the column width\n",
    "        worksheet.column_dimensions[column_letter].width = column_length\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file\n",
    "    df_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the cell below to create a super-table excel file for each table file in the table directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing culex_pipiens-table-1 table...\n",
      "Table culex_pipiens-table-1.txt done in --- 0.0628821849822998 seconds ---\n",
      "Analysing culex_pipiens-table-2 table...\n",
      "Table culex_pipiens-table-2.txt done in --- 0.0488584041595459 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Save the super-table for each table in the tables directory\n",
    "\n",
    "# Import the whole dataframe from the tsv files\n",
    "df = get_dataframe_from_files()\n",
    "\n",
    "for table_file in os.listdir(table_path):\n",
    "\n",
    "    # Create a copy of the dataframe\n",
    "    tmp = df.copy()\n",
    "    \n",
    "    print(\"Analysing\", table_file[:-4], \"table...\")\n",
    "\n",
    "    # get initial time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Generate the dataframe from \n",
    "    tmp = generate_df(tmp, table_file)\n",
    "\n",
    "    # Generate the xlsx file\n",
    "    generate_xlsx(tmp, out_path + title.replace(\" \", \"_\"), table_file[:-4])\n",
    "\n",
    "    print(\"Table\", table_file, \"done in\", \"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    # Delete the copy of the dataframe\n",
    "    del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
